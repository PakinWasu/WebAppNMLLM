# ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô LLM (Ollama) ‡∏ö‡∏ô‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå

## üìã ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°

‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ **Ollama** ‡πÄ‡∏õ‡πá‡∏ô LLM (Large Language Model) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå network configuration

- **‡πÅ‡∏ö‡∏ö Remote LLM**: Backend ‡πÉ‡∏ô Docker ‡∏ä‡∏µ‡πâ‡πÑ‡∏õ‡∏ó‡∏µ‡πà LLM server ‡∏ô‡∏≠‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡πÄ‡∏ä‡πà‡∏ô `http://10.4.15.152:11434`) ‚Äî ‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏ô `backend/.env` ‡πÄ‡∏õ‡πá‡∏ô `OLLAMA_BASE_URL=http://10.4.15.152:11434`
- **‡πÅ‡∏ö‡∏ö Docker**: Backend ‡πÉ‡∏ä‡πâ Ollama container ‡πÉ‡∏ô Docker ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‚Äî ‡∏ï‡∏±‡πâ‡∏á `OLLAMA_BASE_URL=http://ollama:11434`

## üèóÔ∏è ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Docker Network                  ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ Backend  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  Ollama  ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ          ‚îÇ      ‚îÇ          ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ       ‚îÇ                  ‚îÇ             ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

- **Backend** ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö **Ollama** ‡∏ú‡πà‡∏≤‡∏ô Docker network (`http://ollama:11434`)
- ‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏£‡∏±‡∏ô‡πÉ‡∏ô Docker container ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô Docker volume (`ollama-data`)

## üöÄ ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤

### 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Docker Compose Configuration

‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏°‡∏µ Ollama service ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô `docker-compose.yml` ‡πÅ‡∏•‡∏∞ `docker-compose.prod.yml` ‡πÅ‡∏•‡πâ‡∏ß:

```yaml
ollama:
  image: ollama/ollama:latest
  container_name: mnp-ollama-prod
  restart: unless-stopped
  ports:
    - "11434:11434"
  volumes:
    - ollama-data:/root/.ollama
  networks:
    - mnp-network
```

### 2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Environment Variables

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `.env` ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `backend/`:

```bash
cd backend
cp .env.example .env
nano .env
```

‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:

```env
# AI Model Configuration (Ollama)
# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Docker: ‡πÉ‡∏ä‡πâ http://ollama:11434 (‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Ollama container)
# Qwen2.5-coder:32b - ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô technical analysis (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
AI_MODEL_NAME=qwen2.5-coder:32b
AI_MODEL_VERSION=v2-coder-32b
AI_MODEL_ENDPOINT=http://ollama:11434
```

**‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç**: 
- ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö **Production/Development ‡πÉ‡∏ô Docker**: ‡πÉ‡∏ä‡πâ `http://ollama:11434`
- ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö **Development ‡∏ö‡∏ô Host Machine**: ‡πÉ‡∏ä‡πâ `http://host.docker.internal:11434` (‡∏ñ‡πâ‡∏≤ Ollama ‡∏£‡∏±‡∏ô‡∏ö‡∏ô host)
- ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö **Remote LLM Server** (‡πÄ‡∏ä‡πà‡∏ô 10.4.15.152): ‡πÉ‡∏ä‡πâ `OLLAMA_BASE_URL=http://10.4.15.152:11434` ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á backend (‡∏´‡∏£‡∏∑‡∏≠ Docker host) ‡πÑ‡∏õ‡∏ñ‡∏∂‡∏á IP ‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏î‡πâ ‡∏ö‡∏ô LLM server ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (‡πÄ‡∏ä‡πà‡∏ô `ollama pull deepseek-coder-v2:16b`) ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö `OLLAMA_MODEL` ‡πÉ‡∏ô `.env`

### 3. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• LLM

‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å start services ‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•:

```bash
# ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô Ollama container
docker exec -it mnp-ollama-prod bash

# ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ô‡∏µ‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
docker exec -it mnp-ollama-prod ollama pull qwen2.5-coder:32b
```

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏**: ‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô (‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï)

### 4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Ollama container ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
docker ps | grep ollama

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö logs
docker logs mnp-ollama-prod

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å Backend container
docker exec -it mnp-backend-prod curl http://ollama:11434/api/tags

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•
docker exec -it mnp-ollama-prod ollama run qwen2.5-coder:32b "Hello, how are you?"
```

## üìù ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Services

```bash
# Development
docker-compose up -d

# Production
docker-compose -f docker-compose.prod.yml up -d
```

### ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ Ollama

```bash
# ‡∏î‡∏π logs ‡πÅ‡∏ö‡∏ö real-time
docker logs -f mnp-ollama-prod

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
curl http://localhost:11434/api/tags
```

### ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• LLM

1. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç `.env`:
   ```env
   AI_MODEL_NAME=llama3:8b  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
   ```

2. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà:
   ```bash
   docker exec -it mnp-ollama-prod ollama pull llama3:8b
   ```

3. Restart backend:
   ```bash
   docker-compose restart backend
   ```

## üîß ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Backend ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Ollama ‡πÑ‡∏î‡πâ

**‡∏≠‡∏≤‡∏Å‡∏≤‡∏£**: Error message `[ERROR] Ollama call failed: ...`

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç**:

1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Ollama container ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:
   ```bash
   docker ps | grep ollama
   ```

2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö network connectivity:
   ```bash
   docker exec -it mnp-backend-prod ping -c 3 ollama
   ```

3. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö endpoint ‡πÉ‡∏ô `.env`:
   ```bash
   docker exec -it mnp-backend-prod env | grep AI_MODEL_ENDPOINT
   ```
   ‡∏Ñ‡∏ß‡∏£‡πÅ‡∏™‡∏î‡∏á: `AI_MODEL_ENDPOINT=http://ollama:11434`

4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö logs:
   ```bash
   docker logs mnp-backend-prod | grep -i ollama
   docker logs mnp-ollama-prod
   ```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î

**‡∏≠‡∏≤‡∏Å‡∏≤‡∏£**: Error `model not found` ‡∏´‡∏£‡∏∑‡∏≠ `404 Not Found`

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç**:

```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
docker exec -it mnp-ollama-prod ollama list

# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
docker exec -it mnp-ollama-prod ollama pull qwen2.5-coder:32b

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
docker exec -it mnp-ollama-prod ollama list
```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Ollama ‡πÉ‡∏ä‡πâ RAM/CPU ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç**:

1. ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤:
   ```env
   AI_MODEL_NAME=qwen2.5-coder:14b  # ‡πÅ‡∏ó‡∏ô 32b (‡∏™‡∏°‡∏î‡∏∏‡∏•)
   # ‡∏´‡∏£‡∏∑‡∏≠
   AI_MODEL_NAME=qwen2.5-coder:7b   # ‡πÅ‡∏ó‡∏ô 32b (‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤)
   ```

2. ‡∏à‡∏≥‡∏Å‡∏±‡∏î resources ‡πÉ‡∏ô docker-compose:
   ```yaml
   ollama:
     deploy:
       resources:
         limits:
           memory: 4G
           cpus: '2'
   ```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Response ‡∏ä‡πâ‡∏≤‡∏°‡∏≤‡∏Å‡∏´‡∏£‡∏∑‡∏≠ Timeout

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç**:

1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö logs ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏Ç‡∏∂‡πâ‡∏ô:
   ```bash
   docker logs mnp-ollama-prod --tail 50
   ```

2. ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î input (‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏Å‡∏±‡∏î original_content ‡πÄ‡∏õ‡πá‡∏ô 5000 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÅ‡∏•‡πâ‡∏ß)

3. ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ (‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏≠‡∏≤‡∏à‡∏•‡∏î‡∏•‡∏á)

4. ‡πÄ‡∏û‡∏¥‡πà‡∏° timeout ‡πÉ‡∏ô `llm_service.py` (‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô 600 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)

## üéØ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Network Configuration Analysis

### Qwen2.5 Coder Models (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô Technical Analysis)

**Qwen2.5 Coder** ‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô technical analysis, code generation, ‡πÅ‡∏•‡∏∞ code reasoning ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô Network Configuration Analysis ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î

#### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ RAM 32GB+

- `qwen2.5-coder:32b` ‚≠ê (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î) - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î, ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡πà‡∏≤ GPT-4o ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô technical
  - RAM: ~16-20GB
  - Model size: ~18GB
  - ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô Network Configuration Analysis ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
  - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö structured output (JSON) ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏°‡∏≤‡∏Å

#### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ RAM 16-32GB

- `qwen2.5-coder:14b` - ‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
  - RAM: ~8-10GB
  - Model size: ~8GB
  - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏î‡∏µ‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô technical

#### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ RAM 8-16GB

- `qwen2.5-coder:7b` - ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤
  - RAM: ~4-6GB
  - Model size: ~4GB
  - ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏î‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô technical

### Qwen2.5 General Models (‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å)

#### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ RAM 8GB+

- `qwen2.5:7b` - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏î‡∏µ, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á
- `llama3:8b` - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏î‡∏µ‡∏°‡∏≤‡∏Å, ‡πÉ‡∏ä‡πâ RAM ‡∏°‡∏≤‡∏Å
- `mistral:7b` - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏î‡∏µ, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏î‡∏µ

#### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ RAM 4-8GB

- `qwen2.5:3b` - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏î‡∏µ
- `llama3:3b` - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏î‡∏µ
- `phi3:mini` - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏î‡∏µ‡∏°‡∏≤‡∏Å

#### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ RAM ‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 4GB

- `phi3:mini` - ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏•‡πá‡∏Å, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏î‡∏µ
- `tinyllama` - ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏•‡πá‡∏Å‡∏°‡∏≤‡∏Å, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ï‡πà‡∏≥

### ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Qwen2.5 Coder?

1. **Specialized Training**: ‡∏ñ‡∏π‡∏Å train ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô technical/code analysis
2. **Superior Performance**: ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡πà‡∏≤ GPT-4o ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô technical benchmarks
3. **Network Configuration Fit**: ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à configuration syntax, command structures ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤
4. **Structured Output**: ‡∏™‡∏£‡πâ‡∏≤‡∏á structured JSON outputs ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏°‡∏≤‡∏Å
5. **Technical Reasoning**: ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ technical concepts ‡πÑ‡∏î‡πâ‡∏î‡∏µ

## üìä ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Performance

### ‡∏î‡∏π Token Usage ‡πÅ‡∏•‡∏∞ Latency

‡∏î‡∏π‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å API response ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á analysis:

```json
{
  "llm_metrics": {
    "inference_time_ms": 1234.5,
    "token_usage": {
      "prompt_tokens": 500,
      "completion_tokens": 300,
      "total_tokens": 800
    },
    "model_name": "qwen2.5-coder:32b"
  }
}
```

### ‡∏î‡∏π Performance Metrics ‡∏à‡∏≤‡∏Å Database

```bash
# ‡πÄ‡∏Ç‡πâ‡∏≤ MongoDB
docker exec -it mnp-mongo-prod mongo

# ‡∏î‡∏π performance logs
use manage_network_projects
db.performance_logs.find().sort({timestamp: -1}).limit(10).pretty()
```

## üîí Security Considerations

1. **‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ú‡∏¢ Ollama port ‡πÑ‡∏õ‡∏¢‡∏±‡∏á public** (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô):
   - Port 11434 ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£ expose ‡πÑ‡∏õ‡∏¢‡∏±‡∏á public network
   - ‡πÉ‡∏ä‡πâ‡∏ú‡πà‡∏≤‡∏ô Docker network ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô

2. **Backup ‡πÇ‡∏°‡πÄ‡∏î‡∏•** (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£):
   ```bash
   # Backup volume
   docker run --rm -v ollama-data:/data -v $(pwd):/backup alpine tar czf /backup/ollama-backup.tar.gz /data
   ```

3. **Monitor Resource Usage**:
   ```bash
   docker stats mnp-ollama-prod
   ```

## üìö ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

- [Ollama Official Documentation](https://ollama.ai/docs)
- [ANALYSIS_SYSTEM.md](backend/ANALYSIS_SYSTEM.md) - ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏£‡∏∞‡∏ö‡∏ö Analysis
- [README.md](README.md) - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå

## üÜò Support

‡∏´‡∏≤‡∏Å‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠:

1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö logs: `docker logs mnp-ollama-prod`
2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö network: `docker network inspect mnp-network`
3. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö environment variables: `docker exec mnp-backend-prod env | grep AI`
4. ‡∏î‡∏π‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ Ollama: https://ollama.ai/docs
