"""Accuracy Scoring Service for Topology Generation - Based on llm_evaluation.py"""

from typing import Dict, List, Any, Tuple
import re


class TopologyAccuracyScorer:
    """Calculate accuracy scores for topology generation by comparing LLM output with deterministic data"""
    
    def __init__(self):
        pass
    
    def calculate_accuracy(
        self,
        llm_topology: Dict[str, Any],
        deterministic_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Calculate accuracy score by comparing LLM-detected links with deterministic LLDP data.
        
        Args:
            llm_topology: Topology generated by LLM with nodes and edges
            deterministic_data: Dictionary mapping device_name -> {neighbors: [], interfaces: []}
        
        Returns:
            Dict with consistency_score, coverage_score, accuracy_score, and issues
        """
        llm_edges = llm_topology.get("edges", [])
        llm_nodes = llm_topology.get("nodes", [])
        
        # Build deterministic edge set from LLDP neighbors
        deterministic_edges = set()
        for device_name, device_data in deterministic_data.items():
            neighbors = device_data.get("neighbors", [])
            for neighbor in neighbors:
                neighbor_name = neighbor.get("device_name")
                if neighbor_name:
                    # Create bidirectional edge key (sorted to avoid duplicates)
                    edge_key = tuple(sorted([device_name, neighbor_name]))
                    deterministic_edges.add(edge_key)
        
        # Build LLM edge set
        llm_edge_set = set()
        for edge in llm_edges:
            from_dev = edge.get("from", "").strip()
            to_dev = edge.get("to", "").strip()
            if from_dev and to_dev:
                edge_key = tuple(sorted([from_dev, to_dev]))
                llm_edge_set.add(edge_key)
        
        # Calculate consistency: How many LLM edges match deterministic edges?
        matching_edges = llm_edge_set.intersection(deterministic_edges)
        total_deterministic = len(deterministic_edges)
        total_llm = len(llm_edge_set)
        
        if total_deterministic == 0:
            consistency_score = 100.0 if total_llm == 0 else 0.0
        else:
            consistency_score = (len(matching_edges) / total_deterministic) * 100.0
        
        # Calculate coverage: How many deterministic edges were found by LLM?
        if total_deterministic == 0:
            coverage_score = 100.0  # No deterministic edges to cover
        else:
            coverage_score = (len(matching_edges) / total_deterministic) * 100.0
        
        # Calculate precision: How many LLM edges are correct?
        if total_llm == 0:
            precision_score = 100.0 if total_deterministic == 0 else 0.0
        else:
            precision_score = (len(matching_edges) / total_llm) * 100.0
        
        # Identify issues
        issues = []
        
        # Missing edges: deterministic edges not found by LLM
        missing_edges = deterministic_edges - llm_edge_set
        if missing_edges:
            issues.append(f"Missing {len(missing_edges)} deterministic link(s): {', '.join([f'{e[0]}-{e[1]}' for e in list(missing_edges)[:5]])}")
        
        # Hallucinated edges: LLM edges not in deterministic data
        hallucinated_edges = llm_edge_set - deterministic_edges
        if hallucinated_edges:
            issues.append(f"Potential hallucination: {len(hallucinated_edges)} link(s) not found in LLDP data: {', '.join([f'{e[0]}-{e[1]}' for e in list(hallucinated_edges)[:5]])}")
        
        # Check for "Unknown Link" handling
        unknown_links = [e for e in llm_edges if "unknown" in e.get("evidence", "").lower() or "unknown" in e.get("label", "").lower()]
        if unknown_links:
            issues.append(f"Found {len(unknown_links)} 'Unknown Link' entries (good: LLM correctly identified incomplete data)")
        
        # Overall accuracy score (weighted average)
        overall_score = (
            0.4 * consistency_score +  # How well LLM matches deterministic data
            0.4 * coverage_score +     # How many deterministic edges were found
            0.2 * precision_score      # How many LLM edges are correct
        )
        
        return {
            "consistency_score": round(consistency_score, 2),
            "coverage_score": round(coverage_score, 2),
            "precision_score": round(precision_score, 2),
            "accuracy_score": round(overall_score, 2),
            "matching_edges": len(matching_edges),
            "total_deterministic_edges": total_deterministic,
            "total_llm_edges": total_llm,
            "missing_edges_count": len(missing_edges),
            "hallucinated_edges_count": len(hallucinated_edges),
            "issues": issues,
            "summary": self._generate_summary(
                consistency_score, coverage_score, precision_score, overall_score, issues
            )
        }
    
    def _generate_summary(
        self,
        consistency: float,
        coverage: float,
        precision: float,
        overall: float,
        issues: List[str]
    ) -> str:
        """Generate human-readable summary"""
        if overall >= 80:
            status = "Topology generation is highly accurate and reliable."
        elif overall >= 60:
            status = "Topology generation is acceptable but may require manual verification."
        else:
            status = "Topology generation has significant accuracy issues and should be reviewed."
        
        issue_text = "\n".join(f"- {issue}" for issue in issues) if issues else "No critical issues detected."
        
        return f"""Overall Assessment: {status}

Accuracy Metrics:
- Consistency: {consistency:.1f}% (LLM edges matching deterministic LLDP data)
- Coverage: {coverage:.1f}% (Deterministic edges found by LLM)
- Precision: {precision:.1f}% (LLM edges that are correct)

Issues Detected:
{issue_text}
""".strip()


# Singleton instance
topology_accuracy_scorer = TopologyAccuracyScorer()
