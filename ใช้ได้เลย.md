# ใช้ได้เลย

โปรเจคนี้ **ใช้ LLM** (Ollama รันที่ Windows 10.4.15.152, โมเดล deepseek-coder-v2:16b) สำหรับวิเคราะห์ config และ topology

เปิด **Terminal** ในโฟลเดอร์โปรเจค แล้วรันคำสั่งเดียวด้านล่าง  
(จะถามรหัส **sudo** ครั้งเดียวสำหรับติดตั้ง Docker ถ้ายังไม่มี)

```bash
cd /home/nmp/Downloads/WebAppNMLLM
./run-on-ubuntu-server.sh
```

จากนั้นรอจนจบ (ครั้งแรกอาจใช้เวลาหลายนาที เพราะต้องติดตั้ง Docker และ build แอป)

---

## หลังรันเสร็จ

- **เปิดแอปในเบราว์เซอร์:**  
  **http://localhost:8080**  
  หรือถ้าเข้าจากเครื่องอื่น: **http://\<IP-เครื่องนี้\>:8080**

- **Login:**  
  - Username: **admin**  
  - Password: **admin123**  
  (ควรเปลี่ยนรหัสผ่านหลังล็อกอินครั้งแรก)

- **API docs:**  
  http://localhost:8000/docs

---

## คำสั่งที่ใช้บ่อย

```bash
# ⚠️ อัปเดตอะไรก็ตาม (โค้ด, .env, LLM config) ให้ restart Docker เสมอ
./update-and-restart.sh
# หรือ pull จาก git แล้วค่อย restart
./update-and-restart.sh --pull

# ดู logs
docker compose -f docker-compose.prod.yml logs -f

# หยุดแอป
docker compose -f docker-compose.prod.yml down

# เปิดแอปอีกครั้ง (หลังหยุดแล้ว)
docker compose -f docker-compose.prod.yml up -d
```

---

ถ้ารันแล้วมี error ให้ copy ข้อความใน Terminal ส่งมาจะช่วยดูให้ได้
